{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Twitter_Sentiments-Copy1 (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRIqooMT8vPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kehx5UPQ8vP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(r'C:\\Users\\asus\\Downloads\\TwitterSentiment\\train.csv')\n",
        "test = pd.read_csv(r'C:\\Users\\asus\\Downloads\\TwitterSentiment\\test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTv81Arv8vP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train.text\n",
        "train_target = train.airline_sentiment\n",
        "test_data = test.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmHYmS6Q8vQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "stop = stopwords.words('english')\n",
        "stop.remove(\"isn't\")\n",
        "punctuations = list(string.punctuation)\n",
        "stop += punctuations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0PWTx7V8vQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "#nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQjp6yo08vQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# s = \"yes..not\"\n",
        "tt = TweetTokenizer(strip_handles=False)\n",
        "# word_tokenize(s), tt.tokenize(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7vbMXe28vQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "for i in range(len(train_data)):\n",
        "    documents.append([train_data[i], train_target[i]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYI_Fi88vQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import wordnet\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF97Hdjs8vQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def postag(st):\n",
        "    s = str(st)\n",
        "    if s.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif s.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif s.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif s.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpSDoEyv8vQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_words(doc):\n",
        "    output_words = []\n",
        "    words = tt.tokenize(doc)\n",
        "    for word in words:\n",
        "        if (word.lower() not in stop) and (word.isdigit() == False):\n",
        "            pos = pos_tag(word)\n",
        "            out = lemmatizer.lemmatize(word, pos = postag(pos))\n",
        "            output_words.append(out)\n",
        "    return output_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilvNRDrB8vQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents_new = [(clean_words(doc), target) for doc, target in documents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sieDHoNS8vQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_data = [clean_words(doc) for doc in test_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fxvc8_B8vQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_words = []\n",
        "# for doc, tar in documents_new:\n",
        "#     all_words += doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za-q6e478vQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# freq = nltk.FreqDist(all_words)\n",
        "# common_words = freq.most_common(3000)\n",
        "# vocab = [word for word, val in common_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA80ZeFy8vQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def features(doc):\n",
        "#     feature = {}\n",
        "#     for w in vocab:\n",
        "#         feature[w] = w in doc\n",
        "#     return feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiA-1hhC8vQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_data = [(features(doc), target) for doc, target in documents_new]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3DA18iF8vQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clf = nltk.NaiveBayesClassifier.train(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM0rPF8i8vRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clf.show_most_informative_features(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD2lgDEU8vRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_omS_4fs8vRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [\" \".join(doc) for doc, target in documents_new]\n",
        "y_train = [target for doc, target in documents_new]\n",
        "x_test = [\" \".join(data) for data in testing_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6jR9Fba8vRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tr, x_te, y_tr, y_te = train_test_split(x_train, y_train, random_state = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qzqJ2qs8vRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpmZxdle8vRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Count_Vec = CountVectorizer(max_features= 2890, max_df=0.6, tokenizer= tt.tokenize)#, ngram_range=(1,2))\n",
        "x_train_v = Count_Vec.fit_transform(x_train)\n",
        "#x_tr_v = Count_Vec.fit_transform(x_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A8qur9I8vRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count_Vec.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgoDso-R8vRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_v = Count_Vec.transform(x_test)\n",
        "#x_te_v = Count_Vec.transform(x_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP5y_VQl8vRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#svc = SVC()\n",
        "rfc = RandomForestClassifier()\n",
        "Multi = MultinomialNB(alpha=0.27)\n",
        "#svc.fit(x_train_v, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR3c1JeF8vRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multi.fit(x_tr_v, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz9VrEDe8vRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multi.score(x_te_v, y_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KRWGB5u8vRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNuIZynI8vR1",
        "colab_type": "code",
        "colab": {},
        "outputId": "4aee2ccd-d1a9-4af0-d978-6652f3d1ca58"
      },
      "source": [
        "# cv = KFold(n_splits= 4, shuffle= False, random_state= 1)\n",
        "# cross_val_score(Multi, x_train_v, y_train, scoring = 'accuracy', cv = cv, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.771949  , 0.76065574, 0.76211293, 0.77340619])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFie3bNG8vR7",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8bf0b1e-7beb-4c57-8960-216fa49118cc"
      },
      "source": [
        "Multi.fit(x_train_v, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.27, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3lkkDcl8vR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = Multi.predict(x_test_v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-xWfdE78vSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(r'C:\\Users\\asus\\Downloads\\TwitterSentiment\\ypreddcop.csv', y_pred, delimiter=',', fmt=\"%s\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRebeVZo8vSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}